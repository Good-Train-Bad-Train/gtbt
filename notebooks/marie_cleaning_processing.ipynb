{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../goodtrainbadtrain/data/select_2020.csv',encoding='iso-8859-2',sep=';')\n",
    "df2 = pd.read_csv('../goodtrainbadtrain/data/select_2021.csv',encoding='iso-8859-2',sep=';')\n",
    "df3 = pd.read_csv('../goodtrainbadtrain/data/select_2022.csv',encoding='iso-8859-2',sep=';')\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for München and Köln\n",
    "df = df.query(\"bhf in ('München Hbf', 'Köln Hbf', 'Köln Messe/Deutz Gl.11-12')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS AND CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) cleaning of train names \n",
    "#some letters of 'zugnr' are not capitalized\n",
    "df['zugnr'] = df['zugnr'].str.upper()\n",
    "\n",
    "#2)process of 9999 in arrTime and depTime: add new column with info \n",
    "df['start_or_endpoint'] = 'nan'\n",
    "df.loc[df['arrTime'] == 9999, 'start_or_endpoint'] = 'start'\n",
    "df.loc[df['depTime'] == 9999, 'start_or_endpoint'] = 'end'\n",
    "#overwrite 9999 with respective arr/dep time of same observation (in new clean columns)\n",
    "df['arrTime_clean'] = np.where(df['arrTime'] == 9999, df['depTime'], df['arrTime'])\n",
    "df['depTime_clean'] = np.where(df['depTime'] == 9999, df['arrTime'], df['depTime'])\n",
    "\n",
    "#3)some times need to be filled up with 0's. eg. '5' -> 00:05\n",
    "df['arrTime_clean'] = df['arrTime_clean'].astype(str)\n",
    "df['arrTime_clean'] = df['arrTime_clean'].map(lambda a: a.zfill(4))\n",
    "df['depTime_clean'] = df['depTime_clean'].astype(str)\n",
    "df['depTime_clean'] = df['depTime_clean'].map(lambda a: a.zfill(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGENEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0v/92j280qj2j971syqfbthtx0r0000gn/T/ipykernel_12429/3253485097.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['city'] = df['city'].str.replace('Köln Messe/Deutz Gl.11-12','Köln')\n"
     ]
    }
   ],
   "source": [
    "#1)add city feature (merged Köln Hbf/ Messe Deutz)\n",
    "df['city'] = df.bhf\n",
    "df['city'] = df['city'].str.replace('Köln Messe/Deutz Gl.11-12','Köln')\n",
    "df['city'] = df['city'].str.replace('Köln Hbf','Köln')\n",
    "df['city'] = df['city'].str.replace('München Hbf','München')\n",
    "\n",
    "#2) add date column\n",
    "df['date'] = df['datum'] + ' ' + df['arrTime_clean']\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H%M')\n",
    "#3) add month of the year \n",
    "df['weekday'] = df['date'].dt.day_name()\n",
    "#4) add month of the year \n",
    "df['month'] = df['date'].dt.month_name()\n",
    "\n",
    "#time of the day\n",
    "df['time_of_day'] = pd.cut(pd.to_datetime(df.date).dt.hour,\n",
    "       bins=[0, 6, 12, 18, 24],\n",
    "       labels=['night', 'morning', 'afternoon', 'evening'],\n",
    "       right=False,\n",
    "       include_lowest=True)\n",
    "\n",
    "#todo\n",
    "#3) add public holiday\n",
    "#4) add covid lockdown?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD DIRECTON INFO (SO FAR OF SIMPLE JOURNEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "journeys = pd.read_csv('../goodtrainbadtrain/data/journeyindex.csv')\n",
    "\n",
    "#processing\n",
    "journeys = journeys[journeys.leg1_train.notna()] #delete duplicated trips that once go to köln hbf and once to deutz\n",
    "journeys = journeys[journeys.leg2_train.notna()] \n",
    "journeys = journeys[journeys.leg3_train.notna()] \n",
    "\n",
    "journeys = journeys.drop(['Unnamed: 0'],axis=1) \n",
    "journeys['key_ID'] = list(range(journeys.shape[0]))\n",
    "\n",
    "#rename columns (necessary for wide_to_long function)\n",
    "journeys.columns = [ 'date', 'weekday', 'month', 'journey_origin',\n",
    "       'journey_destination', 'journey_start', 'journey_end',\n",
    "       'journey_duration', 'journey_numberlegs', \n",
    "       'train_leg1', 'origin_leg1','destination_leg1', 'start_leg1', 'end_leg1', 'duration_leg1',\n",
    "       'train_leg2', 'origin_leg2', 'destination_leg2', 'start_leg2','end_leg2', 'duration_leg2', \n",
    "       'train_leg3', 'origin_leg3','destination_leg3', 'start_leg3', 'end_leg3', 'duration_leg3', \n",
    "       'key_ID']\n",
    "\n",
    "journeys_long = pd.wide_to_long(df = journeys,\n",
    "                                stubnames=['train', 'origin','destination', 'start', 'end', 'duration'],\n",
    "                                i=['key_ID'],\n",
    "                                j='leg',\n",
    "                                sep = '_',\n",
    "                                suffix='.+').reset_index()\n",
    "\n",
    "#delete empty legs\n",
    "journeys_long = journeys_long[journeys_long.train != '-1']\n",
    "\n",
    "#reorder columns\n",
    "journeys_long = journeys_long[['key_ID', \n",
    " 'journey_origin', 'journey_destination','journey_start','journey_end','journey_duration', 'journey_numberlegs',\n",
    " 'leg', 'train', 'origin', 'destination', 'start', 'end','duration',\n",
    " 'date', 'month','weekday']]\n",
    "\n",
    "\n",
    "def date_transformation(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.split('+', expand=True)[[0]]\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "journeys_long = date_transformation(journeys_long, ['journey_start', 'journey_end']) #, 'start', 'end'])\n",
    "journeys_long['month'] = journeys_long['journey_start'].dt.month_name()\n",
    "journeys_long['weekday'] = journeys_long['journey_start'].dt.day_name()\n",
    "\n",
    "\n",
    "simple_journeys = journeys[journeys.journey_numberlegs == 1]\n",
    "simple_journeys_tomunich = simple_journeys[simple_journeys.journey_destination == \"München Hbf\"].train_leg1.unique()\n",
    "simple_journeys_tocologne = simple_journeys[(simple_journeys.journey_destination == \"Köln Hbf\") | (simple_journeys.journey_destination == \"Köln Messe/Deutz Gl.11-12\")].train_leg1.unique()\n",
    "\n",
    "\n",
    "df['ends_cologne'] = df['zugnr'].isin(simple_journeys_tocologne.tolist())\n",
    "df['ends_munich'] = df['zugnr'].isin(simple_journeys_tomunich.tolist())\n",
    "\n",
    "\n",
    "cologne_mask = (df.ends_cologne) & (df.city == 'Köln')\n",
    "munich_mask = (df.ends_munich) & (df.city == 'München')\n",
    "df = df[cologne_mask | munich_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "München Hbf                         451\n",
       "Frankfurt(Main) Flughafen Fernbf    225\n",
       "Köln Messe/Deutz Gl.11-12           202\n",
       "Mannheim Hbf                        180\n",
       "Köln Hbf                            165\n",
       "Stuttgart Hbf                        81\n",
       "Würzburg Hbf                         41\n",
       "Frankfurt(Main) Hbf                  39\n",
       "Nürnberg Hbf                         10\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD WEATHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) add weather variables\n",
    "df['sharp_date'] = df['date'].dt.round('H')\n",
    "df['sharp_date']  = df.sharp_date.astype('str')\n",
    "\n",
    "cgn_data = pd.read_csv('../goodtrainbadtrain/data/koln.csv')\n",
    "cgn_data['sharp_date']  = cgn_data.time.astype('str')\n",
    "\n",
    "muc_data = pd.read_csv('../goodtrainbadtrain/data/munchen.csv')\n",
    "muc_data['sharp_date'] = muc_data.time.astype('str')\n",
    "\n",
    "weather = {\"Köln\": cgn_data, \"München\": muc_data}\n",
    "\n",
    "\n",
    "total_df =  pd.DataFrame()\n",
    "for station, w_df in weather.items():\n",
    "    station_df = pd.merge(df[df['city'] == station], weather[station], how='left', left_on='sharp_date', right_on='sharp_date') #, right_index=True)\n",
    "    total_df = pd.concat([total_df, station_df])\n",
    "\n",
    "df = total_df.drop(columns=['dwpt', 'rhum', 'wdir', 'pres', 'tsun'])\n",
    "df['snow'] = df['snow'].replace(np.nan, 0)\n",
    "\n",
    "# Load coco file\n",
    "coco = pd.read_csv('../goodtrainbadtrain/data/weather_coco.csv', sep=';')\n",
    "coco.set_index('Code', inplace=True)\n",
    "coco = coco.to_dict()['Weather Condition']\n",
    "\n",
    "# Define new classification for coco\n",
    "new_classes = {\n",
    "    'good': [1, 2],\n",
    "    'medium': [3, 4, 7, 14],\n",
    "    'bad': [5, 8, 10, 12, 15, 17, 19, 21, 23, 24, 25],\n",
    "    'extreme': [6, 9, 11, 13, 16, 18, 20, 22, 26, 27]\n",
    "}\n",
    "\n",
    "# Apply new classification for coco\n",
    "reclass = {}\n",
    "for k, values in new_classes.items():\n",
    "    for v in values:\n",
    "        for c in range(1, 28):\n",
    "            if v == c:\n",
    "                reclass[v] = k\n",
    "\n",
    "reclass = dict(sorted(reclass.items()))\n",
    "df['coco'] = df['coco'].map(reclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TARGET PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) into several categories\n",
    "# adelay-> into categories: no delay, small delay, medium delay, (big delay/cancellation)\n",
    "max = df.adelay.max()\n",
    "bins = [-2, -0.1, 0, 5, 30, max]\n",
    "group_names = ['large delay/cancelled','on time','small delay', 'medium delay', 'large delay/cancelled']\n",
    "df['target'] = pd.cut(df['adelay'], bins, labels=group_names, ordered=False)\n",
    "\n",
    "#value counts of target:\n",
    "#on time                  67336\n",
    "#small delay              28649\n",
    "#medium delay             23617\n",
    "#large delay/cancelled    10677\n",
    "\n",
    "#2) binary target (on time - or not)\n",
    "df['target_binary'] =  (df['adelay'] == 0)*1\n",
    "\n",
    "#3) numeric target (cancelled and extreme values = 120 Min)\n",
    "df['target_numeric'] = df['adelay']\n",
    "df['target_numeric'] = np.where(df['target_numeric'] == -1, 120, df['target_numeric'])\n",
    "df['target_numeric'] = np.where(df['target_numeric'] > 120, 120, df['target_numeric'])\n",
    "#sns.boxplot(df['target_numeric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRELATION / TARGET VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.barplot(x= df.weekday, y=df.target_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.barplot(x= df.month, y=df.target_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40079, 28)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../goodtrainbadtrain/data/data_for_model_2.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fec01d925059a361c1e9f9aa6fb98d44a04ad369f384098a87eb49d1ad96cd7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('shims': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
